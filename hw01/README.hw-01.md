# ДЗ 01: Обзор вакансий Data Engineer по нескольким ресурсам

## Цель

Нужно сделать обзор вакансий Data Engineer по нескольким ресурсам.  
Составить список требуемых навыков, продуктов и технологий.

## Решение

Ниже приведен обзор вакансий по следующим ресурсам:

1. `career.habr.com`
2. `hh.ru`
3. `getmatch`: бот с IT-вакансиями

Далеко не всегда указывается требуемый стаж, поэтому разделил условно на уровни Junior, Middle (в среднем от 2-х лет) и Senior (в среднем от 4-х лет).

Вакансий на уровень Junior меньше, чем для уровней Middle и Senior, требования сложнее ранжировать.

Требования к навыкам и продуктам/технологиям ранжированы в зависимости от частоты упоминаний в вакансиях.

### Уровень **Junior**

Навыки:

* (3) базовые знания о разработке ETL-конвейеров
* (2) создание и модификация объектов в БД (DDL/DML)
* (2) контроль качества данных: валидация, тестирование
* (2) умение подготавливать и выгружать данные
* (1) понимание принципов хранилищ данных (DWH)
* (1) знания Git, Docker
* (1) умение вести техническую документацию

Продукты/технологии:

* (3) Python
* (3) PostgreSQL/Oracle/MS SQL Server
* (2) ClickHouse
* (2) Airflow
* (1) Tableau
* (1) Pandas

### Уровень **Middle**

Навыки:

* (5) знания инструментов разработки ETL/ELT-конвейеров
* (4) контроль качества данных: валидация, тестирование
* (3) понимание концепций построения хранилищ данных (DWH, DataLake)
* (3) знания инструментов мониторинга и алертинга
* (3) знания инструментов оркестрации (DAG)
* (3) знания инструментов интеграции с ML/LLM-системами
* (2) знания DevOps (Git, GitLab, GitHub, Jenkins, Docker)
* (2) опыт получения данных из различных типов API (REST, GraphQL, SOAP)
* (1) знания о работе с витринами данных

Продукты/технологии:

* (5) Python
* (5) PostgreSQL/Oracle/MS SQL Server
* (5) Airflow
* (4) ClickHouse
* (3) Database Tools
* (3) Kafka
* (2) Scala
* (2) Flink
* (2) Parquet
* (2) Greenplum
* (2) S3
* (2) Tableau
* (1) MongoDB
* (1) Java
* (1) Spark
* (1) Kubernetes
* (1) RabbitMQ
* (1) Redis
* (1) Elasticsearch
* (1) Pandas

### Уровень **Senior**

Навыки:

* (5) опыт построения ETL/ELT-конвейеров
* (4) опыт построения хранилищ данных (DWH, DataLake)
* (3) знания DevOps (Git, GitLab, GitHub, Jenkins, Docker)
* (2) знание принципов интеграции систем, взаимодействия по API и протоколам
* (2) знания MLOps и подходов к внедрению моделей ИИ
* (2) оптимизация обработки данных и использования ресурсов
* (1) опыт агрегации данных и построения витрин, систем BI
* (1) знание алгоритмов и структур данных в области Big Data
* (1) знание концепций проектирования (Кимбалл, Инмон, Data Vault, Anchor)
* (1) знание принципов хранения данных (секционирование, сегментирование, использование индексов)
* (1) анализ и оценка бизнес требований

Продукты/технологии:

* (5) Python
* (5) PostgreSQL/Oracle/MS SQL Server
* (5) ClickHouse
* (5) Airflow
* (4) Kafka
* (4) Hadoop
* (3) Spark
* (3) Hive
* (2) Greenplum
* (1) Scala
* (1) Java
* (1) Impala
* (1) Iceberg
* (1) Tableau
* (1) Zepellin
* (1) NiFi
* (1) Parquet
* (1) Pandas
* (1) Superset

## Выводы

* на Junior уровне от Data Engineer требуются в основном:
  * владение Python
  * владение реляционными БД на уровне создания/модификации объектов, написания сложных запросов
  * владение навыками контроля качества данных (валидация, тестирование)
  * умение выполнять предобработку и выгружать данные в хранилища
* переход от уровня Junior выше сразу знаменует качественный скачок в требуемых знаниях и навыках
* на уровнях опыта Middle и Senior крайне важными навыками для соискателей Data Engineer являются:
  * Python (от хороших знаний для Middle, до глубоких для Senior)
  * SQL БД (PostgreSQL, etc.)
  * NoSQL БД (особенно именно ClickHouse)
  * Airflow (оркестрация, DAGи)
  * знания о ETL/ELT-конвейерах (от опыта работы для Middle, до опыта проектирования для Senior)
  * знания о хранилищах данных (от опыта работы для Middle, до опыта построения для Senior)
  * знания из области DevOps (Docker, Git, GitLab, GitHub, Jenkins, CI/CD)
* заметно смещение требований к глубине и ширине навыков при переходе от Middle к Senior:
  * для Middle важно иметь широкий кругозор и опыт с технологиями:  
  как основной набор продуктов для работы с данными (dbt, Flink, Elasticsearch), так и опыт в общих/инфраструктурных технологиях (RabbitMQ, Kafka, Kubernetes, S3, и т.д.)
  * для Senior список продолжает увеличиваться.  
  зачастую именно за счет глубоких требований по продуктам и технологиям обработки данных (Hadoop, Hive, Spark, Zepellin, и т.д.)
  * для Middle больше применимы требования к опыту работы с инструментами (например, для ML, витрин данных и BI) и знания концепций
  * для Senior больше применимы требования уже к опыту проектирования, внедрения и интеграции систем
  * для Senior начинает дополнительно требоваться:
    * знание алгоритмов и структур данных Big Data для проектирования
    * знание принципов хранения данных
    * знание концепций проектирования систем хранения данных
    * умение анализировать и оценивать бизнес требования
